{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rKZHBssI-IbBm8E-aMfGL66uWVLnvOUg",
      "authorship_tag": "ABX9TyOPNzUeu5yzelIjZO8bA/HL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megmarv/Client-Deposit-Prediction/blob/main/DatasetPreparationForML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQgTQptUueKK",
        "outputId": "50fd72b3-b1e3-4a75-f515-b858e32319da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsgVHWZPoRyV",
        "outputId": "cb1c8c90-a740-4434-8270-8d289b0204b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Training Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 41188 entries, 0 to 41187\n",
            "Data columns (total 21 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   age             41188 non-null  int64  \n",
            " 1   job             41188 non-null  object \n",
            " 2   marital         41188 non-null  object \n",
            " 3   education       41188 non-null  object \n",
            " 4   default         41188 non-null  object \n",
            " 5   housing         41188 non-null  object \n",
            " 6   loan            41188 non-null  object \n",
            " 7   contact         41188 non-null  object \n",
            " 8   month           41188 non-null  object \n",
            " 9   day_of_week     41188 non-null  object \n",
            " 10  duration        41188 non-null  int64  \n",
            " 11  campaign        41188 non-null  int64  \n",
            " 12  pdays           41188 non-null  int64  \n",
            " 13  previous        41188 non-null  int64  \n",
            " 14  poutcome        41188 non-null  object \n",
            " 15  emp.var.rate    41188 non-null  float64\n",
            " 16  cons.price.idx  41188 non-null  float64\n",
            " 17  cons.conf.idx   41188 non-null  float64\n",
            " 18  euribor3m       41188 non-null  float64\n",
            " 19  nr.employed     41188 non-null  float64\n",
            " 20  y               41188 non-null  object \n",
            "dtypes: float64(5), int64(5), object(11)\n",
            "memory usage: 6.6+ MB\n",
            "\n",
            "Sample Data:\n",
            "   age        job  marital    education  default housing loan    contact  \\\n",
            "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
            "1   57   services  married  high.school  unknown      no   no  telephone   \n",
            "2   37   services  married  high.school       no     yes   no  telephone   \n",
            "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
            "4   56   services  married  high.school       no      no  yes  telephone   \n",
            "\n",
            "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
            "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
            "\n",
            "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
            "0          93.994          -36.4      4.857       5191.0  no  \n",
            "1          93.994          -36.4      4.857       5191.0  no  \n",
            "2          93.994          -36.4      4.857       5191.0  no  \n",
            "3          93.994          -36.4      4.857       5191.0  no  \n",
            "4          93.994          -36.4      4.857       5191.0  no  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset preprocessing complete. Datasets saved for modeling.\n",
            "Initial Testing Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4119 entries, 0 to 4118\n",
            "Data columns (total 21 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   age             4119 non-null   int64  \n",
            " 1   job             4119 non-null   object \n",
            " 2   marital         4119 non-null   object \n",
            " 3   education       4119 non-null   object \n",
            " 4   default         4119 non-null   object \n",
            " 5   housing         4119 non-null   object \n",
            " 6   loan            4119 non-null   object \n",
            " 7   contact         4119 non-null   object \n",
            " 8   month           4119 non-null   object \n",
            " 9   day_of_week     4119 non-null   object \n",
            " 10  duration        4119 non-null   int64  \n",
            " 11  campaign        4119 non-null   int64  \n",
            " 12  pdays           4119 non-null   int64  \n",
            " 13  previous        4119 non-null   int64  \n",
            " 14  poutcome        4119 non-null   object \n",
            " 15  emp.var.rate    4119 non-null   float64\n",
            " 16  cons.price.idx  4119 non-null   float64\n",
            " 17  cons.conf.idx   4119 non-null   float64\n",
            " 18  euribor3m       4119 non-null   float64\n",
            " 19  nr.employed     4119 non-null   float64\n",
            " 20  y               4119 non-null   object \n",
            "dtypes: float64(5), int64(5), object(11)\n",
            "memory usage: 675.9+ KB\n",
            "\n",
            "Sample Data (Testing Dataset):\n",
            "   age          job  marital          education default  housing     loan  \\\n",
            "0   30  blue-collar  married           basic.9y      no      yes       no   \n",
            "1   39     services   single        high.school      no       no       no   \n",
            "2   25     services  married        high.school      no      yes       no   \n",
            "3   38     services  married           basic.9y      no  unknown  unknown   \n",
            "4   47       admin.  married  university.degree      no      yes       no   \n",
            "\n",
            "     contact month day_of_week  ...  campaign  pdays  previous     poutcome  \\\n",
            "0   cellular   may         fri  ...         2    999         0  nonexistent   \n",
            "1  telephone   may         fri  ...         4    999         0  nonexistent   \n",
            "2  telephone   jun         wed  ...         1    999         0  nonexistent   \n",
            "3  telephone   jun         fri  ...         3    999         0  nonexistent   \n",
            "4   cellular   nov         mon  ...         1    999         0  nonexistent   \n",
            "\n",
            "  emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
            "0         -1.8          92.893          -46.2      1.313       5099.1  no  \n",
            "1          1.1          93.994          -36.4      4.855       5191.0  no  \n",
            "2          1.4          94.465          -41.8      4.962       5228.1  no  \n",
            "3          1.4          94.465          -41.8      4.959       5228.1  no  \n",
            "4         -0.1          93.200          -42.0      4.191       5195.8  no  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "Testing dataset preprocessing complete. Processed datasets saved.\n",
            "Datasets saved to Google Drive:\n",
            "/content/drive/MyDrive/ML/X_balanced.csv\n",
            "/content/drive/MyDrive/ML/y_balanced.csv\n",
            "/content/drive/MyDrive/ML/X_test_preprocessed.csv\n",
            "/content/drive/MyDrive/ML/y_test_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the training dataset\n",
        "data_path = '/content/drive/MyDrive/ML/bank-additional-full.csv'\n",
        "df = pd.read_csv(data_path, sep=';')\n",
        "\n",
        "# Display initial information\n",
        "print(\"Initial Training Dataset Info:\")\n",
        "df.info()\n",
        "print(\"\\nSample Data:\")\n",
        "print(df.head())\n",
        "\n",
        "# 1. Handle missing values (\"unknown\")\n",
        "missing_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan']\n",
        "for col in missing_cols:\n",
        "    mode_value = df[col].mode()[0]\n",
        "    df[col] = df[col].replace('unknown', mode_value)\n",
        "\n",
        "# 2. Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# 3. Drop or exclude the `duration` column\n",
        "df.drop(columns=['duration'], inplace=True)\n",
        "\n",
        "# 4. One-hot encode categorical variables and scale numeric features\n",
        "categorical_columns = [\n",
        "    'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
        "    'contact', 'month', 'day_of_week', 'poutcome'\n",
        "]\n",
        "numeric_columns = [\n",
        "    'age', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
        "    'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'\n",
        "]\n",
        "\n",
        "# Transformations\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_columns),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "X = df.drop(columns=['y'])\n",
        "y = df['y'].apply(lambda x: 1 if x == 'yes' else 0)  # Convert target to binary (0, 1)\n",
        "\n",
        "# Apply preprocessing\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# 5. Handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X_preprocessed, y)\n",
        "\n",
        "# Save processed training data\n",
        "pd.DataFrame(X_balanced).to_csv('/content/X_balanced.csv', index=False)\n",
        "pd.DataFrame({'y': y_balanced}).to_csv('/content/y_balanced.csv', index=False)\n",
        "\n",
        "print(\"Training dataset preprocessing complete. Datasets saved for modeling.\")\n",
        "\n",
        "# Load the testing dataset\n",
        "test_data_path = '/content/drive/MyDrive/ML/bank-additional.csv'\n",
        "df_test = pd.read_csv(test_data_path, sep=';')\n",
        "\n",
        "# Display initial information\n",
        "print(\"Initial Testing Dataset Info:\")\n",
        "df_test.info()\n",
        "print(\"\\nSample Data (Testing Dataset):\")\n",
        "print(df_test.head())\n",
        "\n",
        "# 1. Handle missing values (\"unknown\") using mode values from training dataset\n",
        "for col in missing_cols:\n",
        "    mode_value = df[col].mode()[0]\n",
        "    df_test[col] = df_test[col].replace('unknown', mode_value)\n",
        "\n",
        "# 2. Drop the `duration` column\n",
        "df_test.drop(columns=['duration'], inplace=True)\n",
        "\n",
        "# Apply preprocessing to the testing dataset\n",
        "X_test_original = df_test.drop(columns=['y'])\n",
        "y_test_original = df_test['y'].apply(lambda x: 1 if x == 'yes' else 0)  # Convert target to binary (0, 1)\n",
        "\n",
        "X_test_preprocessed = preprocessor.transform(X_test_original)\n",
        "\n",
        "# Save processed testing data\n",
        "pd.DataFrame(X_test_preprocessed).to_csv('/content/X_test_preprocessed.csv', index=False)\n",
        "pd.DataFrame({'y': y_test_original}).to_csv('/content/y_test_preprocessed.csv', index=False)\n",
        "\n",
        "print(\"Testing dataset preprocessing complete. Processed datasets saved.\")\n",
        "\n",
        "# Mount Google Drive\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Define paths for saving\n",
        "save_dir = '/content/drive/MyDrive/ML'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "X_balanced_path = os.path.join(save_dir, 'X_balanced.csv')\n",
        "y_balanced_path = os.path.join(save_dir, 'y_balanced.csv')\n",
        "X_test_path = os.path.join(save_dir, 'X_test_preprocessed.csv')\n",
        "y_test_path = os.path.join(save_dir, 'y_test_preprocessed.csv')\n",
        "\n",
        "# Save processed datasets\n",
        "pd.DataFrame(X_balanced).to_csv(X_balanced_path, index=False)\n",
        "pd.DataFrame({'y': y_balanced}).to_csv(y_balanced_path, index=False)\n",
        "pd.DataFrame(X_test_preprocessed).to_csv(X_test_path, index=False)\n",
        "pd.DataFrame({'y': y_test_original}).to_csv(y_test_path, index=False)\n",
        "\n",
        "print(f\"Datasets saved to Google Drive:\\n\"\n",
        "      f\"{X_balanced_path}\\n\"\n",
        "      f\"{y_balanced_path}\\n\"\n",
        "      f\"{X_test_path}\\n\"\n",
        "      f\"{y_test_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JrVd1w8AdE1m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}