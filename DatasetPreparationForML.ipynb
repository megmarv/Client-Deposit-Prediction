{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1rKZHBssI-IbBm8E-aMfGL66uWVLnvOUg",
      "authorship_tag": "ABX9TyOLuucd/kezrb3DNICMwaw4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/megmarv/Client-Deposit-Prediction/blob/main/DatasetPreparationForML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This Document contains the process of preparing the relevant datasets for further use"
      ],
      "metadata": {
        "id": "N4VPr9DextI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "-tcpAlu1x6WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import os\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "oc99fMtjx_7x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the bank-additional-full dataset for training"
      ],
      "metadata": {
        "id": "6tsRCxxKyPwa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsgVHWZPoRyV",
        "outputId": "80913345-5ceb-413a-deec-99acd451ad4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset preprocessing complete. Datasets saved for modeling.\n"
          ]
        }
      ],
      "source": [
        "# Load the training dataset\n",
        "data_path = '/content/drive/MyDrive/ML/bank-additional-full.csv'\n",
        "df = pd.read_csv(data_path, sep=';')\n",
        "\n",
        "# 1. Handle missing values (\"unknown\")\n",
        "missing_cols = ['job', 'marital', 'education', 'default', 'housing', 'loan']\n",
        "for col in missing_cols:\n",
        "    mode_value = df[col].mode()[0]\n",
        "    df[col] = df[col].replace('unknown', mode_value)\n",
        "\n",
        "# 2. Remove duplicate rows\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# 3. Drop or exclude the `duration` column\n",
        "df.drop(columns=['duration'], inplace=True)\n",
        "\n",
        "# 4. One-hot encode categorical variables and scale numeric features\n",
        "categorical_columns = [\n",
        "    'job', 'marital', 'education', 'default', 'housing', 'loan',\n",
        "    'contact', 'month', 'day_of_week', 'poutcome'\n",
        "]\n",
        "numeric_columns = [\n",
        "    'age', 'campaign', 'pdays', 'previous', 'emp.var.rate',\n",
        "    'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'\n",
        "]\n",
        "\n",
        "# Transformations\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_columns),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "X = df.drop(columns=['y'])\n",
        "y = df['y'].apply(lambda x: 1 if x == 'yes' else 0)  # Convert target to binary (0, 1)\n",
        "\n",
        "# Apply preprocessing\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# 5. Handle class imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X_preprocessed, y)\n",
        "\n",
        "# Save processed training data\n",
        "pd.DataFrame(X_balanced).to_csv('/content/X_balanced.csv', index=False)\n",
        "pd.DataFrame({'y': y_balanced}).to_csv('/content/y_balanced.csv', index=False)\n",
        "\n",
        "print(\"Training dataset preprocessing complete. Datasets saved for modeling.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the dataset for Testing"
      ],
      "metadata": {
        "id": "TrJHIdjky-BX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the testing dataset\n",
        "test_data_path = '/content/drive/MyDrive/ML/bank-additional.csv'\n",
        "df_test = pd.read_csv(test_data_path, sep=';')\n",
        "\n",
        "# 1. Handle missing values (\"unknown\") using mode values from training dataset\n",
        "for col in missing_cols:\n",
        "    mode_value = df[col].mode()[0]\n",
        "    df_test[col] = df_test[col].replace('unknown', mode_value)\n",
        "\n",
        "# 2. Drop the `duration` column\n",
        "df_test.drop(columns=['duration'], inplace=True)\n",
        "\n",
        "# Apply preprocessing to the testing dataset\n",
        "X_test_original = df_test.drop(columns=['y'])\n",
        "y_test_original = df_test['y'].apply(lambda x: 1 if x == 'yes' else 0)  # Convert target to binary (0, 1)\n",
        "\n",
        "X_test_preprocessed = preprocessor.transform(X_test_original)\n",
        "\n",
        "# Save processed testing data\n",
        "pd.DataFrame(X_test_preprocessed).to_csv('/content/X_test_preprocessed.csv', index=False)\n",
        "pd.DataFrame({'y': y_test_original}).to_csv('/content/y_test_preprocessed.csv', index=False)\n",
        "\n",
        "print(\"Testing dataset preprocessing complete. Processed datasets saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeMqJBR7y8yY",
        "outputId": "da5a823e-76ad-4ce6-e262-40c4be5a0caa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing dataset preprocessing complete. Processed datasets saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the prepared and preprocessed datasets to the drive"
      ],
      "metadata": {
        "id": "cRZ4Eo5-zHiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Define paths for saving\n",
        "save_dir = '/content/drive/MyDrive/ML'\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "X_balanced_path = os.path.join(save_dir, 'X_balanced.csv')\n",
        "y_balanced_path = os.path.join(save_dir, 'y_balanced.csv')\n",
        "X_test_path = os.path.join(save_dir, 'X_test_preprocessed.csv')\n",
        "y_test_path = os.path.join(save_dir, 'y_test_preprocessed.csv')\n",
        "\n",
        "# Save processed datasets\n",
        "pd.DataFrame(X_balanced).to_csv(X_balanced_path, index=False)\n",
        "pd.DataFrame({'y': y_balanced}).to_csv(y_balanced_path, index=False)\n",
        "pd.DataFrame(X_test_preprocessed).to_csv(X_test_path, index=False)\n",
        "pd.DataFrame({'y': y_test_original}).to_csv(y_test_path, index=False)\n",
        "\n",
        "print(f\"Datasets saved to Google Drive:\\n\"\n",
        "      f\"{X_balanced_path}\\n\"\n",
        "      f\"{y_balanced_path}\\n\"\n",
        "      f\"{X_test_path}\\n\"\n",
        "      f\"{y_test_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vi1rcBJlzMAg",
        "outputId": "1e028a0f-a286-4c0c-9dd3-76caf336c98a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets saved to Google Drive:\n",
            "/content/drive/MyDrive/ML/X_balanced.csv\n",
            "/content/drive/MyDrive/ML/y_balanced.csv\n",
            "/content/drive/MyDrive/ML/X_test_preprocessed.csv\n",
            "/content/drive/MyDrive/ML/y_test_preprocessed.csv\n"
          ]
        }
      ]
    }
  ]
}